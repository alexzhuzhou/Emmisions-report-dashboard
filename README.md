# Chevron-SQ - Sustainability Scoring Platform

A comprehensive platform for analyzing and scoring companies' sustainability metrics, particularly focused on CNG (Compressed Natural Gas) adoption potential. The application combines intelligent web scraping, AI-powered analysis, and a modern web interface to provide detailed sustainability insights.

## ğŸ—ï¸ Project Architecture

- **Frontend**: Next.js 15 with TypeScript, Tailwind CSS, and React 19
- **Backend**: FastAPI with SQLAlchemy and PostgreSQL
- **AI Scraper**: Python-based intelligent web scraping with OpenAI integration
- **Database**: PostgreSQL with comprehensive sustainability metrics schema
- **State Management**: React Context API and localStorage for client-side persistence

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** (v18 or higher)
- **Python** (v3.8 or higher)
- **PostgreSQL** (v12 or higher)
- **Git**

### 1. Clone and Setup

```bash
git clone <repository-url>
cd Chevron-SQ
```

### 2. Database Setup

1. **Install PostgreSQL** and create a database:
```bash
# Create database
createdb chevron_sq_db

# Or using psql
psql -U postgres
CREATE DATABASE chevron_sq_db;
\q
```

2. **Run the database schema**:
```bash
psql -U postgres -d chevron_sq_db -f schema.sql
```

### 3. Backend Setup

#### FastAPI Backend

1. **Navigate to the FastAPI directory**:
```bash
cd fastAPI_backend
```

2. **Create and activate virtual environment**:
```bash
python -m venv venv
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

3. **Install dependencies**:
```bash
pip install -r requirements.txt
```

4. **Set up environment variables** (create `.env` file):
```bash
# Database configuration
DATABASE_URL=postgresql://username:password@localhost:5432/chevron_sq_db

# OpenAI API (for AI analysis)
OPENAI_API_KEY=your_openai_api_key

# For Search Functionality
GOOGLE_CSE_ID=

# Email configuration (optional)
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_USER=your_email@gmail.com
EMAIL_PASSWORD=your_app_password
```

5. **Start the FastAPI server**:
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at [http://localhost:8000](http://localhost:8000)
API documentation: [http://localhost:8000/docs](http://localhost:8000/docs)

#### AI Scraper Backend

1. **Navigate to the scraper directory**:
```bash
cd backend/src/scraper
```

2. **Install scraper dependencies**:
```bash
pip install -r requirements.txt
```

3. **Install Playwright browsers** (required for web scraping):
```bash
playwright install
```

### 4. Frontend Setup

1. **Return to project root**:
```bash
cd ../../../
```

2. **Install Node.js dependencies**:
```bash
npm install
```

3. **Start the development server**:
```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to see the application.

## ğŸ“ Codebase Organization

```
Chevron-SQ/
â”œâ”€â”€ src/                          # Next.js frontend (App Router)
â”‚   â”œâ”€â”€ app/                      # App router pages
â”‚   â”‚   â”œâ”€â”€ dashboard/           # Main dashboard with sustainability metrics
â”‚   â”‚   â”œâ”€â”€ home/                # Search page
â”‚   â”‚   â”œâ”€â”€ loading/             # Loading screen during analysis
â”‚   â”‚   â”œâ”€â”€ saved/               # Saved reports management
â”‚   â”‚   â””â”€â”€ layout.tsx           # Root layout with navigation
â”‚   â”œâ”€â”€ components/              # React components
â”‚   â”‚   â”œâ”€â”€ ui/                  # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ dashboard-cards.tsx  # Dashboard metric cards
â”‚   â”‚   â”œâ”€â”€ emissiongoal.tsx     # Emission goals visualization
â”‚   â”‚   â”œâ”€â”€ piechart.tsx         # Chart components
â”‚   â”‚   â””â”€â”€ protected-sidebar.tsx # Navigation sidebar
â”‚   â”œâ”€â”€ hooks/                   # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useNavigationWarning.ts # Navigation warning logic
â”‚   â”‚   â””â”€â”€ useClearTabsOnRouteChange.ts # Tab management
â”‚   â”œâ”€â”€ services/                # API service layer
â”‚   â”‚   â””â”€â”€ api.ts               # API client functions
â”‚   â”œâ”€â”€ types/                   # TypeScript type definitions
â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â””â”€â”€ config/                  # Configuration files
â”œâ”€â”€ fastAPI_backend/             # FastAPI backend
â”‚   â”œâ”€â”€ routers/                 # API route handlers
â”‚   â”‚   â”œâ”€â”€ company_routes.py    # Company CRUD operations
â”‚   â”‚   â”œâ”€â”€ search_routes.py     # Search and analysis endpoints
â”‚   â”‚   â”œâ”€â”€ saved_reports.py     # Saved reports management
â”‚   â”‚   â””â”€â”€ dashboard_routes.py  # Dashboard data endpoints
â”‚   â”œâ”€â”€ models.py                # SQLAlchemy database models
â”‚   â”œâ”€â”€ database.py              # Database configuration
â”‚   â”œâ”€â”€ config.py                # Backend configuration
â”‚   â”œâ”€â”€ main.py                  # FastAPI application entry
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ backend/                     # AI Scraper system
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ scraper/             # Core scraping logic
â”‚       â”‚   â”œâ”€â”€ main_ai_scraper.py # Main scraper orchestration
â”‚       â”‚   â”œâ”€â”€ ai_criteria_analyzer.py # AI analysis logic
â”‚       â”‚   â”œâ”€â”€ crawler/         # Web crawling components
â”‚       â”‚   â”œâ”€â”€ analysis/        # Data analysis modules
â”‚       â”‚   â””â”€â”€ utils/           # Scraper utilities
â”‚       â”œâ”€â”€ search/              # Google search integration
â”‚       â””â”€â”€ EmailService/        # Email notifications
â”œâ”€â”€ public/                      # Static assets
â”‚   â””â”€â”€ truck-icon.svg          # Application favicon
â””â”€â”€ schema.sql                  # Database schema
```

## ğŸ”„ Application Flow & Logic

### 1. User Journey

1. **Search Initiation** (`/home` page)
   - User enters company name
   - Frontend calls `/api/search/companies` endpoint
   - Backend checks database first (cache-first approach)

2. **Data Retrieval Logic**
   - **Cache Hit**: If company exists in database, return formatted data
   - **Cache Miss**: If not found, trigger AI scraper analysis
   - **Loading State**: User sees loading screen with progress indicators

3. **AI Analysis Process** (when cache miss)
   - Google search for company sustainability information
   - Web scraping of relevant pages and PDFs
   - AI-powered analysis using OpenAI
   - Extraction of sustainability metrics
   - Generation of overall CNG adoption score

4. **Results Display** (`/dashboard` page)
   - Sustainability metrics visualization
   - CNG fleet analysis
   - Emission goals tracking
   - Alternative fuels assessment
   - Clean energy partnerships
   - Regulatory pressure analysis

5. **Data Persistence**
   - Results stored in localStorage temporarily
   - User can save to database or discard
   - Saved reports accessible via `/saved` page

### 2. Key Components

#### Frontend Architecture

- **App Router**: Next.js 15 App Router for file-based routing
- **Client Components**: Interactive components with `'use client'` directive
- **Server Components**: Static components for better performance
- **State Management**: Combination of React Context and localStorage
- **Navigation**: Protected routes with warning dialogs for unsaved changes

#### Backend Architecture

- **FastAPI**: Modern Python web framework with automatic API docs
- **SQLAlchemy**: ORM for database operations
- **PostgreSQL**: Relational database for data persistence
- **CORS**: Configured for frontend communication
- **Async/Await**: Non-blocking I/O operations

#### AI Scraper System

- **Playwright**: Browser automation for dynamic content
- **OpenAI Integration**: GPT models for intelligent analysis
- **Google Custom Search API**: Google search results
- **Trafilatura**: Web content extraction
- **PyMuPDF**: PDF processing capabilities

### 3. Database Schema

#### Core Tables

- **`Companies`**: Company information and metadata
- **`SustainabilityMetrics`**: Core sustainability metrics and CNG adoption scores
- **`MetricSources`**: Evidence sources for each metric

#### Summary Tables

- **`FleetSummary`**: CNG fleet analysis summaries
- **`EmissionsSummary`**: Emissions reporting and goals summaries
- **`AltFuelsSummary`**: Alternative fuels usage summaries
- **`CleanEnergyPartnersSummary`**: Clean energy partnerships summaries
- **`RegulatoryPressureSummary`**: Regulatory pressure analysis summaries

### 4. API Endpoints

#### Search & Analysis
- `GET /api/search/companies` - Smart company search
- `POST /api/search/save-company` - Save analysis results
- `GET /api/search/company/exists/{name}` - Check if company exists

#### Dashboard & Reports
- `GET /api/dashboard/companies` - Get all companies
- `GET /api/saved-reports/` - Get saved reports
- `DELETE /api/search/company/by-name/{name}` - Delete company

## ğŸ› ï¸ Development Features

### Frontend Development
- **Hot Reload**: Automatic refresh on code changes
- **TypeScript**: Full type safety and IntelliSense
- **Tailwind CSS**: Utility-first CSS framework
- **ESLint**: Code linting and formatting
- **Turbopack**: Fast bundling for development

### Backend Development
- **Auto-reload**: Uvicorn with `--reload` flag
- **API Documentation**: Auto-generated Swagger docs
- **Type Hints**: Full Python type annotations
- **Error Handling**: Comprehensive error tracking
- **Database Migrations**: SQLAlchemy-based schema management

### AI Scraper Development
- **Modular Design**: Separate modules for different analysis types
- **Configurable**: YAML-based configuration files
- **Testable**: Unit tests for core functionality
- **Logging**: Comprehensive logging for debugging

## ğŸ”§ Configuration

### Environment Variables

#### Frontend (`.env.local`)
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_FRONTEND_URL=http://localhost:3000
```

#### Backend (`.env`)
```bash
DATABASE_URL=postgresql://username:password@localhost:5432/chevron_sq_db
OPENAI_API_KEY=your_openai_api_key
GOOGLE_CSE_ID=your_key
ENVIRONMENT=development
```

### Database Configuration

The application uses PostgreSQL with the following connection string format:
```
postgresql://username:password@host:port/database_name
```

## ğŸ§ª Testing

### Frontend Testing
```bash
npm run lint          # Run ESLint
npm run build         # Build for production
```

### Backend Testing
```bash
# Navigate to backend directory
cd fastAPI_backend

## ğŸš€ Deployment

### Development
```bash
# Terminal 1 - Backend
cd fastAPI_backend
uvicorn main:app --reload

# Terminal 2 - Frontend
npm run dev
```


## ğŸ†˜ Troubleshooting

### Common Issues

1. **Database Connection Error**
   - Verify PostgreSQL is running
   - Check database credentials in `.env`
   - Ensure database exists and schema is loaded

2. **Frontend Can't Connect to Backend**
   - Verify backend is running on port 8000
   - Check CORS configuration
   - Ensure `BACKEND_URL` in `globals.ts` is correct

3. **AI Scraper Not Working**
   - Verify OpenAI API key is set
   - Check SerpAPI key for Google search
   - Ensure Playwright browsers are installed

4. **Port Already in Use**
   - Change ports in configuration files
   - Kill existing processes using the ports

### Getting Help

- Review the console logs for error messages
- Verify all environment variables are set correctly
- Ensure all dependencies are installed
- please reach out to myurkovsky@ucdavis.edu for post-handoff troubleshooting
